{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOFau2tRycbOLja3JgBKEIa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["\n","from numpy import unique,argmax\n","from tensorflow.keras.datasets.mnist import load_data\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Flatten,Dense\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import MaxPool2D\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.utils import plot_model\n","from matplotlib import pyplot as plt\n","import numpy as np"],"metadata":{"id":"2bYF8me--DJW"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9HdwNCWmxhJb"},"outputs":[],"source":["# prompt: how to load a vedio with values for neral network\n","\n","import numpy as np\n","import cv2\n","\n","# Load the video\n","video = cv2.VideoCapture('/content/mnist_dream.mp4')\n","\n","# Get the video's dimensions\n","width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","# Create a numpy array to store the video frames\n","frames = np.zeros((height, width, 3, 10))\n","\n","# Read the first 10 frames of the video\n","for i in range(10):\n","  ret, frame = video.read()\n","  frames[:, :, :, i] = frame\n","\n","# Normalize the pixel values of the frames\n","frames = frames / 255.0\n","\n","# The frames array now contains the first 10 frames of the video, normalized for use in a neural network.\n"]},{"cell_type":"code","source":["img = 255 - img  #img corresponds to each frame that is captured\n","  pad_color = 0\n","  img = np.pad(img, ((0,0), (0,1280-720), (0,0)), mode='constant', constant_values=(pad_color))\n","\n","    line_type = cv2.LINE_AA\n","    font_face = cv2.FONT_HERSHEY_SIMPLEX\n","    font_scale = 1.3\n","    thickness = 2\n","    x, y = 740, 60\n","    color = (255, 255, 255)\n","\n","    text = \"Neural Network Output:\"\n","    cv2.putText(img, text=text, org=(x, y), fontScale=font_scale, fontFace=font_face, thickness=thickness,\n","                    color=color, lineType=line_type)\n","\n","    text = \"Input:\"\n","    cv2.putText(img, text=text, org=(30, y), fontScale=font_scale, fontFace=font_face, thickness=thickness,\n","                    color=color, lineType=line_type)\n","\n","    y = 130\n","    for i, p in enumerate(perc):\n","        if i == guess: color = (255, 218, 158)\n","        else: color = (100, 100, 100)\n","\n","        rect_width = 0\n","        if p > 0: rect_width = int(p * 3.3)\n","\n","        rect_start = 180\n","        cv2.rectangle(img, (x+rect_start, y-5), (x+rect_start+rect_width, y-20), color, -1)\n","\n","        text = '{}: {:>3}%'.format(i, int(p))\n","        cv2.putText(img, text=text, org=(x, y), fontScale=font_scale, fontFace=font_face, thickness=thickness,\n","                    color=color, lineType=line_type)\n","        y += 60\n","\n","    # if you don't want to save the output as a video, set this to False\n","    save_video = True\n","\n","    if save_video:\n","        if vw is None:\n","            codec = cv2.VideoWriter_fourcc(*'DIVX')\n","            vid_width_height = img.shape[1], img.shape[0]\n","            vw = cv2.VideoWriter(mnist_prediction_path, codec, 30, vid_width_height)\n","        # 15 fps above doesn't work robustly so we right frame twice at 30 fps\n","        vw.write(img)\n","        vw.write(img)\n","\n","    # scale down image for display\n","    img_disp = cv2.resize(img, (0,0), fx=0.5, fy=0.5)\n","    cv2_imshow(img_disp)\n","    IPython.display.clear_output(wait=True)\n","\n","cap.release()\n","if vw is not None:\n","    vw.release()\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"UbW3aiOeyLn4","executionInfo":{"status":"error","timestamp":1715315872305,"user_tz":-330,"elapsed":508,"user":{"displayName":"Aiswariya","userId":"03349859674286245296"}},"outputId":"ac556d99-232e-453c-d361-d850c2c0361d"},"execution_count":null,"outputs":[{"output_type":"error","ename":"IndentationError","evalue":"unexpected indent (<ipython-input-4-46e23a88d1d3>, line 2)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-46e23a88d1d3>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    pad_color = 0\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"OIhsg8CW4S05"},"execution_count":null,"outputs":[]}]}